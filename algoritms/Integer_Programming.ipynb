{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ea8835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpyencoder in d:\\programming\\anaconda\\envs\\optimization\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.14.3 in d:\\programming\\anaconda\\envs\\optimization\\lib\\site-packages (from numpyencoder) (1.22.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\admin\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpyencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a00f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.linear_solver import pywraplp\n",
    "from ortools.init import pywrapinit\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import glob\n",
    "#LINK_PROJECT = Path(os.path.abspath(__file__)).parent.parent\n",
    "from numpyencoder import NumpyEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d78d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IP(data, time_limit):\n",
    "    # Opening JSON file\n",
    "    N = data['N']; m = data['m']; M = data['M']; d = data['d']; s = data['s']; e = data['e']\n",
    "    d = dict(zip([*range(1, N + 1)], d))\n",
    "    s = dict(zip([*range(1, N + 1)], s))\n",
    "    e = dict(zip([*range(1, N + 1)], e))\n",
    "\n",
    "    solution = {}\n",
    "    solver = pywraplp.Solver.CreateSolver('SAT')\n",
    "    infinity = solver.infinity()\n",
    "\n",
    "    last_pos_day = max(e.values()) + 1\n",
    "    #print(max(e))\n",
    "\n",
    "    x = dict() # row as field, column as day\n",
    "    for field in range(1, N + 1):\n",
    "        x[field] = dict()\n",
    "        for day in range(last_pos_day):\n",
    "            x[field][day] = solver.IntVar(0, 1, f'x[{field}][{day}]')\n",
    "\n",
    "    productivity = dict()\n",
    "    day_to_harvest = dict()\n",
    "    for day in range(last_pos_day):\n",
    "        productivity[day] = solver.IntVar(0, infinity, f'productivity_day_{day}')\n",
    "        day_to_harvest[day] = solver.IntVar(0, 1, f'harvest_in_day_{day}')\n",
    "\n",
    "    min_productivity_per_day = solver.IntVar(0, infinity, f'min_productivity_per_day')\n",
    "    max_productivity_per_day = solver.IntVar(0, infinity, f'max_productivity_per_day')\n",
    "\n",
    "    for field in range(1, N + 1):\n",
    "        constraint = solver.RowConstraint(1, 1, f'day to harvest field {field}')\n",
    "        for day in range(last_pos_day):\n",
    "            constraint.SetCoefficient(x[field][day], 1)\n",
    "\n",
    "    # for field in range(1, N + 1):\n",
    "    #     print(d[field])\n",
    "\n",
    "    # 1 <= (1 - day_to_harvest)N + x1 + x2 + ... + xN <= N\n",
    "    for day in range(last_pos_day):\n",
    "        constraint = solver.RowConstraint(1 - N, 0, f'assure to harvest only when having admission in day {day}')\n",
    "        constraint.SetCoefficient(day_to_harvest[day], -N)\n",
    "        for field in range(1, N + 1):\n",
    "            constraint.SetCoefficient(x[field][day], 1)\n",
    "\n",
    "    for day in range(last_pos_day):\n",
    "        # m <= (1 - day_to_harvest)m + x1d1 + x2d2 + ... + xNdN <= M\n",
    "        constraint = solver.RowConstraint(0, M - m, f'productivity not surpass M and at least m in day {day}')\n",
    "        constraint.SetCoefficient(day_to_harvest[day], -m)\n",
    "        for field in range(1, N + 1):\n",
    "            constraint.SetCoefficient(x[field][day], d[field])\n",
    "\n",
    "    for day in range(last_pos_day):\n",
    "        constraint = solver.RowConstraint(0, 0, f'productivity in day {day}')\n",
    "        constraint.SetCoefficient(productivity[day], -1)\n",
    "        for field in range(1, N + 1):\n",
    "            constraint.SetCoefficient(x[field][day], d[field])\n",
    "\n",
    "    for day in range(last_pos_day):\n",
    "        # min_productivity_per_day <= M*(1 - day_to_harvest) + productivity\n",
    "        constraint = solver.RowConstraint(-M, infinity, f'min productivity must not surpass productivity of field {field}')\n",
    "        constraint.SetCoefficient(day_to_harvest[day], -M)\n",
    "        constraint.SetCoefficient(min_productivity_per_day, -1)\n",
    "        constraint.SetCoefficient(productivity[day], 1)\n",
    "\n",
    "        constraint = solver.RowConstraint(0, infinity, f'max productivity must not below productivity of field {field}')\n",
    "        constraint.SetCoefficient(productivity[day], -1)\n",
    "        constraint.SetCoefficient(max_productivity_per_day, 1)\n",
    "\n",
    "    for field in range(1, N + 1):\n",
    "        constraint = solver.RowConstraint(s[field], e[field], f'day to harvest must be valid in field {field}')\n",
    "        for day in range(last_pos_day):\n",
    "            constraint.SetCoefficient(x[field][day], day)\n",
    "\n",
    "\n",
    "\n",
    "    objective = solver.Objective()\n",
    "    objective.SetCoefficient(max_productivity_per_day, 1)\n",
    "    objective.SetCoefficient(min_productivity_per_day, -1)\n",
    "    objective.SetMinimization()\n",
    "    \n",
    "    if time_limit:\n",
    "        solver.set_time_limit(time_limit)\n",
    "    start_time = time.time()\n",
    "    status = solver.Solve()\n",
    "    end_time = time.time()\n",
    "    solution[\"time\"] = end_time - start_time\n",
    "\n",
    "    if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "        solution[\"obj\"] = objective.Value()\n",
    "        solution[\"field\"] = []\n",
    "        for field in range(1, N + 1):\n",
    "            for day in range(last_pos_day):\n",
    "                if x[field][day].solution_value() == 1:\n",
    "                    solution[\"field\"].append(day)\n",
    "    else:\n",
    "        #print('No solution!')\n",
    "        solution[\"obj\"] = \"No Solution\"\n",
    "        \n",
    "    return solution\n",
    "\n",
    "\n",
    "def import_data(input_file):\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "        return data\n",
    "    \n",
    "def export(output_file, solution):\n",
    "    if len(solution) == 3:\n",
    "        with open(output_file, \"w+\") as f:\n",
    "            json.dump({\"Time\": solution[\"time\"], \"Result\": solution[\"obj\"],\n",
    "                      \"Solution\": solution[\"field\"]}, f, cls=NumpyEncoder)\n",
    "    else:\n",
    "        with open(output_file, \"w+\") as f:\n",
    "            json.dump({\"Time\": solution[\"time\"], \"Result\": solution[\"obj\"]}, f, cls=NumpyEncoder)\n",
    "    \n",
    "def process(input_file, output_file, time_limit):\n",
    "    data = import_data(input_file)\n",
    "    solution = IP(data, time_limit)\n",
    "    export(output_file, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db265d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  Type1Small  | Name:  sample_10_10_15.json\n",
      "Type:  Type1Small  | Name:  sample_10_20_30.json\n",
      "Type:  Type1Small  | Name:  sample_10_30_50.json\n",
      "Type:  Type1Small  | Name:  sample_10_40_75.json\n",
      "Type:  Type1Small  | Name:  sample_10_50_100.json\n",
      "Type:  Type1Small  | Name:  sample_20_10_15.json\n",
      "Type:  Type1Small  | Name:  sample_20_20_30.json\n",
      "Type:  Type1Small  | Name:  sample_20_30_50.json\n",
      "Type:  Type1Small  | Name:  sample_20_40_75.json\n",
      "Type:  Type1Small  | Name:  sample_20_50_100.json\n",
      "Type:  Type1Small  | Name:  sample_30_10_15.json\n",
      "Type:  Type1Small  | Name:  sample_30_20_30.json\n",
      "Type:  Type1Small  | Name:  sample_30_30_50.json\n",
      "Type:  Type1Small  | Name:  sample_30_40_75.json\n",
      "Type:  Type1Small  | Name:  sample_30_50_100.json\n",
      "Type:  Type1Small  | Name:  sample_40_10_15.json\n",
      "Type:  Type1Small  | Name:  sample_40_20_30.json\n",
      "Type:  Type1Small  | Name:  sample_40_30_50.json\n",
      "Type:  Type1Small  | Name:  sample_40_40_75.json\n",
      "Type:  Type1Small  | Name:  sample_40_50_100.json\n",
      "Type:  Type1Small  | Name:  sample_50_10_15.json\n",
      "Type:  Type1Small  | Name:  sample_50_20_30.json\n",
      "Type:  Type1Small  | Name:  sample_50_30_50.json\n",
      "Type:  Type1Small  | Name:  sample_50_40_75.json\n",
      "Type:  Type1Small  | Name:  sample_50_50_100.json\n",
      "Type:  Type2Small  | Name:  sample_10_10_15.json\n",
      "Type:  Type2Small  | Name:  sample_10_20_30.json\n",
      "Type:  Type2Small  | Name:  sample_10_30_50.json\n",
      "Type:  Type2Small  | Name:  sample_10_40_75.json\n",
      "Type:  Type2Small  | Name:  sample_10_50_100.json\n",
      "Type:  Type2Small  | Name:  sample_20_10_15.json\n",
      "Type:  Type2Small  | Name:  sample_20_20_30.json\n",
      "Type:  Type2Small  | Name:  sample_20_30_50.json\n",
      "Type:  Type2Small  | Name:  sample_20_40_75.json\n",
      "Type:  Type2Small  | Name:  sample_20_50_100.json\n",
      "Type:  Type2Small  | Name:  sample_30_10_15.json\n",
      "Type:  Type2Small  | Name:  sample_30_20_30.json\n",
      "Type:  Type2Small  | Name:  sample_30_30_50.json\n",
      "Type:  Type2Small  | Name:  sample_30_40_75.json\n",
      "Type:  Type2Small  | Name:  sample_30_50_100.json\n",
      "Type:  Type2Small  | Name:  sample_40_10_15.json\n",
      "Type:  Type2Small  | Name:  sample_40_20_30.json\n",
      "Type:  Type2Small  | Name:  sample_40_30_50.json\n",
      "Type:  Type2Small  | Name:  sample_40_40_75.json\n",
      "Type:  Type2Small  | Name:  sample_40_50_100.json\n",
      "Type:  Type2Small  | Name:  sample_50_10_15.json\n",
      "Type:  Type2Small  | Name:  sample_50_20_30.json\n",
      "Type:  Type2Small  | Name:  sample_50_30_50.json\n",
      "Type:  Type2Small  | Name:  sample_50_40_75.json\n",
      "Type:  Type2Small  | Name:  sample_50_50_100.json\n",
      "Type:  Type3Small  | Name:  sample_10_10_15.json\n",
      "Type:  Type3Small  | Name:  sample_10_20_30.json\n",
      "Type:  Type3Small  | Name:  sample_10_30_50.json\n",
      "Type:  Type3Small  | Name:  sample_10_40_75.json\n",
      "Type:  Type3Small  | Name:  sample_10_50_100.json\n",
      "Type:  Type3Small  | Name:  sample_20_10_15.json\n",
      "Type:  Type3Small  | Name:  sample_20_20_30.json\n",
      "Type:  Type3Small  | Name:  sample_20_30_50.json\n",
      "Type:  Type3Small  | Name:  sample_20_40_75.json\n",
      "Type:  Type3Small  | Name:  sample_20_50_100.json\n",
      "Type:  Type3Small  | Name:  sample_30_10_15.json\n",
      "Type:  Type3Small  | Name:  sample_30_20_30.json\n",
      "Type:  Type3Small  | Name:  sample_30_30_50.json\n",
      "Type:  Type3Small  | Name:  sample_30_40_75.json\n",
      "Type:  Type3Small  | Name:  sample_30_50_100.json\n",
      "Type:  Type3Small  | Name:  sample_40_10_15.json\n",
      "Type:  Type3Small  | Name:  sample_40_20_30.json\n",
      "Type:  Type3Small  | Name:  sample_40_30_50.json\n",
      "Type:  Type3Small  | Name:  sample_40_40_75.json\n",
      "Type:  Type3Small  | Name:  sample_40_50_100.json\n",
      "Type:  Type3Small  | Name:  sample_50_10_15.json\n",
      "Type:  Type3Small  | Name:  sample_50_20_30.json\n",
      "Type:  Type3Small  | Name:  sample_50_30_50.json\n",
      "Type:  Type3Small  | Name:  sample_50_40_75.json\n",
      "Type:  Type3Small  | Name:  sample_50_50_100.json\n",
      "Type:  Type4Small  | Name:  sample_10_10_15.json\n",
      "Type:  Type4Small  | Name:  sample_10_20_30.json\n",
      "Type:  Type4Small  | Name:  sample_10_30_50.json\n",
      "Type:  Type4Small  | Name:  sample_10_40_75.json\n",
      "Type:  Type4Small  | Name:  sample_10_50_100.json\n",
      "Type:  Type4Small  | Name:  sample_20_10_15.json\n",
      "Type:  Type4Small  | Name:  sample_20_20_30.json\n",
      "Type:  Type4Small  | Name:  sample_20_30_50.json\n",
      "Type:  Type4Small  | Name:  sample_20_40_75.json\n",
      "Type:  Type4Small  | Name:  sample_20_50_100.json\n",
      "Type:  Type4Small  | Name:  sample_30_10_15.json\n",
      "Type:  Type4Small  | Name:  sample_30_20_30.json\n",
      "Type:  Type4Small  | Name:  sample_30_30_50.json\n",
      "Type:  Type4Small  | Name:  sample_30_40_75.json\n",
      "Type:  Type4Small  | Name:  sample_30_50_100.json\n",
      "Type:  Type4Small  | Name:  sample_40_10_15.json\n",
      "Type:  Type4Small  | Name:  sample_40_20_30.json\n",
      "Type:  Type4Small  | Name:  sample_40_30_50.json\n",
      "Type:  Type4Small  | Name:  sample_40_40_75.json\n",
      "Type:  Type4Small  | Name:  sample_40_50_100.json\n",
      "Type:  Type4Small  | Name:  sample_50_10_15.json\n",
      "Type:  Type4Small  | Name:  sample_50_20_30.json\n",
      "Type:  Type4Small  | Name:  sample_50_30_50.json\n",
      "Type:  Type4Small  | Name:  sample_50_40_75.json\n",
      "Type:  Type4Small  | Name:  sample_50_50_100.json\n",
      "Type:  Type5Small  | Name:  sample_10_10_15.json\n",
      "Type:  Type5Small  | Name:  sample_10_20_30.json\n",
      "Type:  Type5Small  | Name:  sample_10_30_50.json\n",
      "Type:  Type5Small  | Name:  sample_10_40_75.json\n",
      "Type:  Type5Small  | Name:  sample_10_50_100.json\n",
      "Type:  Type5Small  | Name:  sample_20_10_15.json\n",
      "Type:  Type5Small  | Name:  sample_20_20_30.json\n",
      "Type:  Type5Small  | Name:  sample_20_30_50.json\n",
      "Type:  Type5Small  | Name:  sample_20_40_75.json\n",
      "Type:  Type5Small  | Name:  sample_20_50_100.json\n",
      "Type:  Type5Small  | Name:  sample_30_10_15.json\n",
      "Type:  Type5Small  | Name:  sample_30_20_30.json\n",
      "Type:  Type5Small  | Name:  sample_30_30_50.json\n",
      "Type:  Type5Small  | Name:  sample_30_40_75.json\n",
      "Type:  Type5Small  | Name:  sample_30_50_100.json\n",
      "Type:  Type5Small  | Name:  sample_40_10_15.json\n",
      "Type:  Type5Small  | Name:  sample_40_20_30.json\n",
      "Type:  Type5Small  | Name:  sample_40_30_50.json\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(\"..\\\\data\\\\data_v2\\\\*Small*\\\\**.json\"):\n",
    "    datatype, name = path.split(\"\\\\\")[-2:]\n",
    "    print(\"Type: \", datatype, \" | Name: \", name)\n",
    "    input_file = f\"../data/data_v2/{datatype}/{name}\"\n",
    "    output_file = f\"../results/data_v2/{datatype}/integer_programming/result_{name}\"\n",
    "    time_limit = 600000\n",
    "    process(input_file, output_file, time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18907d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d0984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4b688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281c738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac6aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ebb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda0ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e3000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9b51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8620428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f0743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f316b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
